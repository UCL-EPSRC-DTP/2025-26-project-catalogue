# The infrastructuralisation of AI: business logics and policy implications

## Project ID: **2531ad1576**
(You will need this ID for your application)

Research Theme: [Artificial Intelligence and Robotics](../themes/artificial-intelligence-and-robotics.md)

UCL Lead department: [${department}](../departments/science-technology-engineering-and-public-policy.md)

[Department Website](https://www.ucl.ac.uk/steapp)

Lead Supervisor: [Roser Pujadas](https://profiles.ucl.ac.uk/93849)

### Project Summary:

Research shows that personalisation of content in digital platforms such as social media can be discriminatory, exploit vulnerabilities, and create echo chambers (Cohen 2023; Renieris 2023; Suser et al. 2019). It can also involve tracking and manipulating users’ behaviour online (Zuboff 2019). This is, in part, fueled by business models that rely on advertisement and attention rents (Cheng 2021; O’Reilly et al. 2024), the existence of data brokers (Ruschemeier 2023), and enabled through technological means. APIs, cookies, pixels, and fingerprints facilitate tracking, and the exchange of data between systems from different organisations (MacKenzie 2021) and the creation of distributed infrastructures (Pujadas et al. 2024). The embeddedness of Artificial Intelligence (AI) within these infrastructures is enabling automated real-time analytics, bidding, optimization, and personalisation behind the scenes.
As part of a broader research programme, you will be working with Roser Pujadas on the study of how the infrastructuralisation of AI –including the use of AI techniques such as synthetic data to circumvent current regulation (Helm et al. 2024; Renieris 2023)— is involved in the personalization of content presented in social media, the distribution of fake news, polarization of discourse, etc. You will follow a technographic approach –i.e. a “detailed examination of the material aspects of technology by directly reading various publicly available documents” (van der Vlist et al. 2024)— to uncover the material features of these infrastructures and the embeddedness of AI. The aim is to assess the potential threats that these new technological configurations pose to human rights, and derive policy implications.
We are looking for a prospective PhD student able to conduct interdisciplinary, sociotechnical research, interested in developing new methodologies, and with a good understanding of technology and social / policy implications. Potential candidate’s background: digital technology policy, social media, cyberlaw, information systems, critical data studies, or computer sciences
